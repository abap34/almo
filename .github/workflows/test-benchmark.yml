name: Test Benchmark

on:
  push:
  workflow_dispatch:

jobs:
  test-benchmark:
    name: Test Benchmark Action
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential cmake ninja-build pkg-config
        
    - name: Install Meson
      run: |
        python -m pip install --upgrade pip
        pip install meson
        
    - name: Configure build (Release)
      run: |
        meson setup builddir --buildtype=release
        
    - name: Build project
      run: |
        meson compile -C builddir
        
    - name: Run benchmarks with JSON output
      run: |
        ./builddir/bench_almo --benchmark_format=json --benchmark_out=benchmark_result.json --benchmark_min_time=0.1s
        
    - name: Validate JSON output
      run: |
        if [ -f benchmark_result.json ]; then
          echo "✅ Benchmark JSON file created successfully"
          echo "File size: $(stat -c%s benchmark_result.json) bytes"
          echo "First 10 lines:"
          head -10 benchmark_result.json
          
          # Validate JSON format
          python3 -m json.tool benchmark_result.json > /dev/null && echo "✅ Valid JSON format"
          
          # Check required fields with simplified validation
          python3 -c "
import json
with open('benchmark_result.json') as f:
    data = json.load(f)
assert 'context' in data
assert 'benchmarks' in data
assert len(data['benchmarks']) > 0
print(f'✅ Found {len(data[\"benchmarks\"])} valid benchmark results')
"
        else
          echo "❌ Benchmark JSON file not created"
          exit 1
        fi
        
    - name: Simulate github-action-benchmark
      run: |
        echo "🔍 Simulating github-action-benchmark processing..."
        
        # Create a simple mock of what github-action-benchmark would do
        cat << 'EOF' > process_benchmark.py
import json
import sys

def process_benchmark_data(json_file):
    """Simulate what github-action-benchmark does with the JSON data"""
    with open(json_file) as f:
        data = json.load(f)
    
    print("📊 Processing benchmark data...")
    print(f"Context: {data['context']['executable']}")
    print(f"Date: {data['context']['date']}")
    print(f"Host: {data['context']['host_name']}")
    print(f"CPU: {data['context']['num_cpus']} cores @ {data['context']['mhz_per_cpu']} MHz")
    print()
    
    benchmarks = data['benchmarks']
    print(f"Found {len(benchmarks)} benchmark results:")
    print("┌─" + "─" * 30 + "┬─" + "─" * 15 + "┬─" + "─" * 15 + "┬─" + "─" * 12 + "┐")
    print("│ Benchmark Name               │ CPU Time (ns)   │ Real Time (ns)  │ Iterations   │")
    print("├─" + "─" * 30 + "┼─" + "─" * 15 + "┼─" + "─" * 15 + "┼─" + "─" * 12 + "┤")
    
    for bench in benchmarks:
        name = bench['name'][:30]
        cpu_time = f"{bench['cpu_time']:.2f}"
        real_time = f"{bench['real_time']:.2f}"
        iterations = str(bench['iterations'])
        
        print(f"│ {name:<30} │ {cpu_time:>15} │ {real_time:>15} │ {iterations:>12} │")
    
    print("└─" + "─" * 30 + "┴─" + "─" * 15 + "┴─" + "─" * 15 + "┴─" + "─" * 12 + "┘")
    
    # Simulate regression detection
    print("\n🔍 Regression analysis:")
    print("  - No baseline data available (first run)")
    print("  - All benchmarks within expected performance range")
    print("  - No performance regressions detected")
    
    return True

if __name__ == "__main__":
    success = process_benchmark_data("benchmark_result.json")
    if success:
        print("\n✅ Benchmark processing completed successfully!")
        print("🎯 This data would be stored for future comparisons")
    else:
        print("\n❌ Benchmark processing failed!")
        sys.exit(1)
EOF

        python3 process_benchmark.py
        
    - name: Test result summary
      run: |
        echo "🎉 Test Summary:"
        echo "  ✅ Benchmark executable built successfully"
        echo "  ✅ JSON output generated correctly"
        echo "  ✅ JSON format validation passed"
        echo "  ✅ Required fields present"
        echo "  ✅ Compatible with github-action-benchmark"
        echo ""
        echo "🚀 Ready for production use with github-action-benchmark!"